{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马尔科夫模型Hidden Markov Model HMM\n",
    "参考https://www.cnblogs.com/pinard/p/6955871.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 暴力求解\n",
    " 1. 生成所有的隐藏状态序列 I\n",
    " 2. 对每个隐藏状态序列， 计算观测序列出现的概率\n",
    " \n",
    "对于含有 N 个隐藏状态的hmm模型，设生成的序列长度为 T，那么共可生成$N^T$中隐藏状态序列，计算概率需要遍历隐藏序列 T，故时间复杂度为$O(TN^T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "[[0, 0, 0], [0, 0, 1], [0, 0, 2], [0, 1, 0], [0, 1, 1], [0, 1, 2], [0, 2, 0], [0, 2, 1], [0, 2, 2], [1, 0, 0], [1, 0, 1], [1, 0, 2], [1, 1, 0], [1, 1, 1], [1, 1, 2], [1, 2, 0], [1, 2, 1], [1, 2, 2], [2, 0, 0], [2, 0, 1], [2, 0, 2], [2, 1, 0], [2, 1, 1], [2, 1, 2], [2, 2, 0], [2, 2, 1], [2, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "def generate_hidden_sequences(N,T):\n",
    "    c = []\n",
    "    def backtracking(r):\n",
    "        if len(r) == T:\n",
    "            c.append([i for i in r])\n",
    "        else:\n",
    "            for i in range(N):\n",
    "                r.append(i)\n",
    "                backtracking(r)\n",
    "                r.pop()\n",
    "    backtracking([])\n",
    "    return c \n",
    "c = generate_hidden_sequences(3,3)\n",
    "print(len(c))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'-----------'\n",
      "[0.2, 0.4, 0.4]\n",
      "[[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]\n",
      "[[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]\n",
      "'-----------'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "class HMM():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.p = [0.2,0.4,0.4]\n",
    "        self.A = [[0.5,.2,.3],[.3,.5,.2],[.2,.3,.5]]\n",
    "        self.B = [[.5,.5],[.4,.6],[.7,.3]]\n",
    "    def print_hmm(self):\n",
    "        pp('-----------')\n",
    "        pp(self.p)\n",
    "        pp(self.A)\n",
    "        pp(self.B)\n",
    "        pp('-----------')\n",
    "h = HMM()\n",
    "h.print_hmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 150 µs, sys: 0 ns, total: 150 µs\n",
      "Wall time: 157 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = [0,1,0]\n",
    "def prob():\n",
    "    p = [] \n",
    "    for i in c:\n",
    "        _p = h.p[i[0]] * h.B[i[0]][t[0]]\n",
    "        for k in range(1,len(i)):\n",
    "            _p *= h.A[i[k-1]][i[k]] * h.B[i[k]][t[k]]\n",
    "        p.append(_p)\n",
    "    return sum(p) \n",
    "prob()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用前向算法求概率\n",
    "上述暴力求解当隐藏状态$N$很大时,时间复杂度很高.\n",
    "\n",
    "通过定义一个隐藏状态的前向概率,可以使用动态规划递推的方式求解出$P(O|\\lambda)$\n",
    "\n",
    "具体的,前向概率定义为$\\alpha_t=P(o_1,o_2,...,o_t,i_t=q_i|\\lambda)$. 也即在观测序列为$(o_1,o_2,...,o_t)$,并且隐藏状态为$i_t = q_i$时的概率.\n",
    "\n",
    "可以由$\\alpha_t$推断出$\\alpha_{t+1}$.\n",
    "\n",
    "由于 hmm 认为当前状态只受前一状态影响,并且当前观测只受当前隐藏状态影响, 那么可以推出:\n",
    "$$\n",
    "\\alpha_{t+1}(i) = [\\sum_{j=1}^N\\alpha_t(j)a_{ji}]b_i(o_{t+1})\n",
    "$$\n",
    "翻译成白话文就是: \n",
    "> 已有之前所有状态的前向概率,计算到达状态 i 的前向概率: 由于每个隐藏状态均可到达隐藏状态 i,因此需要遍历所有可能的隐藏状态到 i 的概率,当遍历完成后,得到的概率就是观测序列为$o_1,0_2,...,o_t$,隐藏状态为 i 的概率,再乘以由状态 i 转移到观测$o_{t+1}$的概率$b_i(o_{t+1})$,即可得到$\\alpha_{t+1}(i)$乘以观测转移概率即可得到定义的前向概率.\n",
    "\n",
    "可以看到,上述的计算是完全依赖于 hmm 的两个假设的.\n",
    "\n",
    "## 时间复杂度\n",
    "待处理的序列长度为$T$, 处理每个$o_t$时需要时间$O(N^2)$, 所以最后的时间复杂度为:\n",
    "$$\n",
    "O(N^2T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.130218\n",
      "CPU times: user 223 µs, sys: 0 ns, total: 223 µs\n",
      "Wall time: 202 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def forward_algo(sequence):\n",
    "    # lens of hidden state\n",
    "    N = len(h.A)\n",
    "    # dp array. actually only one vector is enough since t+1 only need t.\n",
    "    forward_p = []\n",
    "    \n",
    "    # first calculate the initial forward prob.\n",
    "    p = []\n",
    "    for i in range(N):\n",
    "        p.append(h.p[i] * h.B[i][sequence[0]])\n",
    "    forward_p.append(p)\n",
    "    # then dp: 2,3...\n",
    "    for i in range(1,len(sequence)): # O(T)\n",
    "        # i is the hidden state, and we need calculate it's forward_p according to forward_p[-1]\n",
    "        a = forward_p[-1]\n",
    "        p = []\n",
    "        for k in range(N): # O(N**2)\n",
    "            p.append(sum([a[j] * h.A[j][k] for j in range(N)]) * h.B[k][sequence[i]])\n",
    "        forward_p.append(p)\n",
    "    return sum(forward_p[-1])\n",
    "r = forward_algo(t)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用后向算法求概率\n",
    "后向概率的定义:\n",
    "$$\n",
    "\\beta_t(i) = P(o_{t+1},o_{t+2},...,o_T|i_{t}=q_i,\\lambda)\n",
    "$$\n",
    "即代表时刻$t$的隐藏状态为$q_i$,t+1 到 T 时刻的观测序列为$o_{t+1},...,o_T$的概率,此概率即为后向概率.\n",
    "可以推出后向概率的递推关系式:\n",
    "$$\n",
    "\\beta_t(i) = \\sum_{j=1}^{N}a_{ij}\\beta_{t+1}(j)b_j(o_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71 µs, sys: 11 µs, total: 82 µs\n",
      "Wall time: 90.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def backward_algo(sequence):\n",
    "    N = len(h.A)\n",
    "    backward_p = []\n",
    "    # init the beta\n",
    "    backward_p.append([1] * N)\n",
    "    for i in range(len(sequence)-2,-1,-1):\n",
    "        b = backward_p[-1]\n",
    "        p = []\n",
    "        for k in range(N):\n",
    "            p.append(sum([h.A[k][j] * b[j] * h.B[j][sequence[i+1]] for j in range(N)])) \n",
    "        backward_p.append(p)\n",
    "    b = backward_p[-1]\n",
    "    return sum([h.p[i] * h.B[i][sequence[0]] * b[i] for i in range(N)])\n",
    "backward_algo(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "前向后向算法其实就是 dp 问题,确定 dp 推导公式后**严格**按照公式迭代求就完事了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM参数的求解\n",
    "HMM 参数$\\lambda=(A,B,\\pi)$\n",
    "\n",
    "有以下两种情况:\n",
    "1. 数据集$D$包含观测序列和隐藏状态序列,即$d=[O,I]$\n",
    "2. 数据集$D$仅有观测序列,没有隐藏序列\n",
    "\n",
    "对于第一种情况,直接利用频数统计即可获得所有参数(实际可看成极大似然估计)\n",
    "\n",
    "对于第二种情况,需要使用 EM 算法. 由于鲍姆-韦尔奇算法在提出时还没有 EM 算法,故现在还是说使用鲍姆-韦尔奇算法求解第二种情况.\n",
    "\n",
    "其思想就是根据 EM 算法求期望,然后求最值.\n",
    "\n",
    "最后的迭代就是根据推导公式对每个样本求概率,然后更新参数,直至收敛.\n",
    "\n",
    "具体可参考文首的参考链接.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 维特比算法解码隐藏状态序列\n",
    "问题概述: 给定模型和观测序列，求给定观测序列条件下，最可能出现的对应的隐藏状态序列\n",
    "\n",
    "参考:\n",
    "\n",
    "https://www.cnblogs.com/pinard/p/6991852.html\n",
    "\n",
    "https://www.zhihu.com/question/20136144\n",
    "\n",
    "https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95\n",
    "\n",
    "https://www.cnblogs.com/pinard/p/6677078.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
